name: shenron-cu126

services:
  vllm:
    build:
      context: ..
      dockerfile: docker/Dockerfile.cu126
    image: tytn/shenron:0.1.1-vllm-cu126
    command: ["bash","-lc","source /opt/shenron/.venv/bin/activate && exec bash /generated/vllm_start.sh"]
    volumes:
      - $HOME/.cache/huggingface:/root/.cache/huggingface
      - ./.generated:/generated:ro
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]

  onwards:
    build:
      context: ..
      dockerfile: docker/Dockerfile.onwards
    image: tytn/shenron:0.1.1-onwards
    depends_on:
      - vllm
    command: ["bash","-lc","exec bash /generated/onwards_start.sh"]
    volumes:
      - ./.generated:/generated:ro
    ports:
      - "${ONWARDS_PORT:-3000}:3000"

  prometheus:
    build:
      context: .
      dockerfile: Dockerfile.prometheus
    image: tytn/shenron:0.1.1-prometheus
    depends_on:
      - vllm
    volumes:
      - ./.generated/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"