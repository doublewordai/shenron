# syntax=docker/dockerfile:1
# ============================================================
# Stage 1: NVSHMEM Builder
# ============================================================
FROM pytorch/pytorch:2.8.0-cuda12.9-cudnn9-devel AS deepep-builder

# Add rdma libraries and build dependencies
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends \
    git build-essential ninja-build cmake pkg-config wget \
    librdmacm-dev rdma-core libfabric-dev libibverbs-dev \
    devscripts debhelper fakeroot \
 && rm -rf /var/lib/apt/lists/*

# Build GDRCopy
RUN cd /tmp && \
    wget https://github.com/NVIDIA/gdrcopy/archive/refs/tags/v2.5.1.tar.gz && \
    tar -xf v2.5.1.tar.gz && \
    cd gdrcopy-2.5.1/packages/ && \
    CUDA=/usr/local/cuda ./build-deb-packages.sh -t -k

RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends git \
 && dpkg -i /tmp/gdrcopy-2.5.1/packages/libgdrapi_*.deb

# Build NVSHMEM - Need GDRCOPY and IBGDA support for DeepEP all2all kernels
RUN set -eux; \
    cd /tmp; \
    wget https://developer.nvidia.com/downloads/assets/secure/nvshmem/nvshmem_src_3.2.5-1.txz; \
    mkdir -p nvshmem_src_3.2.5-1; \
    tar xf nvshmem_src_3.2.5-1.txz -C nvshmem_src_3.2.5-1; \
    cd nvshmem_src_3.2.5-1/nvshmem_src; \
    mkdir -p build; \
    cd build; \
    cmake \
        -DNVSHMEM_PREFIX=/opt/nvshmem-3.2.5 \
        -DCMAKE_CUDA_ARCHITECTURES=90a \
        -DNVSHMEM_MPI_SUPPORT=0 \
        -DNVSHMEM_PMIX_SUPPORT=0 \
        -DNVSHMEM_USE_GDRCOPY=1 \
        -DNVSHMEM_IBGDA_SUPPORT=1 \
        -DNVSHMEM_BUILD_TESTS=0 \
        -DNVSHMEM_BUILD_EXAMPLES=0 \
        -DNVSHMEM_BUILD_HYDRA_LAUNCHER=1 \
        -DNVSHMEM_BUILD_TXZ_PACKAGE=1 \
        -G Ninja \
        ..; \
        ninja; \
        ninja install; \
        rm -rf /tmp/nvshmem_src_3.2.5-1.txz


# ============================================================
# Stage 2: Rust Build (onwards binary)
# ============================================================
FROM rust:1.88 AS rust-builder

WORKDIR /build

# Copy the onwards submodule source
COPY onwards/ ./

# Build the binary in release mode
RUN cargo build --release

# ============================================================
# Stage 3: vLLM/Python Dependencies (slow, cache separately)
# ============================================================
FROM pytorch/pytorch:2.8.0-cuda12.9-cudnn9-devel AS python-deps

RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends curl

RUN curl -LsSf https://astral.sh/uv/install.sh | sh \
 && ln -s /root/.local/bin/uv /usr/local/bin/uv

# flashinfer-cubin installs pre-compiled CUDA kernels for vLLM
# Needed for FP8-MOE models
RUN uv venv /opt/shenron/.venv && \
    . /opt/shenron/.venv/bin/activate && \
    uv pip install vllm==0.13.0 --torch-backend=auto && \
    uv pip install flashinfer-cubin==0.5.3 flashinfer-python==0.5.3 && \
    uv pip install flashinfer-jit-cache==0.5.3 --index-url https://flashinfer.ai/whl/cu129


# ============================================================
# Stage 4: Final Runtime Image
# ============================================================
FROM pytorch/pytorch:2.8.0-cuda12.9-cudnn9-devel AS runtime

# Copy built artifacts from builder stages
COPY --from=deepep-builder /opt/nvshmem-3.2.5 /opt/nvshmem-3.2.5
COPY --from=deepep-builder /tmp/gdrcopy-2.5.1/packages/*.deb /tmp/gdrcopy/
COPY --from=deepep-builder /opt/conda/lib/python3.11/site-packages/deep_ep* /opt/conda/lib/python3.11/site-packages/
COPY --from=rust-builder /build/target/release/onwards /usr/local/bin/onwards
COPY --from=python-deps /opt/shenron/.venv /opt/shenron/.venv
COPY --from=python-deps /root/.local/bin/uv /usr/local/bin/uv

# Install minimal runtime dependencies
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends \
    librdmacm-dev rdma-core libfabric-dev libibverbs-dev \
    git curl openssh-server librdmacm1 libibverbs1 libfabric1 \
    prometheus \
 && dpkg -i /tmp/gdrcopy/libgdrapi_*.deb \
 && rm -rf /tmp/gdrcopy

# NVSHMEM Environment
ENV NVSHMEM_HOME=/opt/nvshmem-3.2.5
ENV LD_LIBRARY_PATH=${NVSHMEM_HOME}/lib:/usr/local/cuda/lib64:${LD_LIBRARY_PATH}
ENV PATH="/opt/shenron/.venv/bin:/opt/hydra/bin:/usr/local/cuda/bin:${PATH}"
ENV VLLM_HAS_FLASHINFER_CUBIN=1

# DeepEP installation - TODO: pull into the deepep-builder stage
RUN git clone https://github.com/deepseek-ai/DeepEP /deepep && \
    cd /deepep && \
    NVSHMEM_DIR=/opt/nvshmem-3.2.5 python setup.py install

# SSH configuration
RUN mkdir -p /var/run/sshd /root/.ssh && \
    chmod 700 /root/.ssh && \
    sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin prohibit-password/' /etc/ssh/sshd_config && \
    sed -i 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' /etc/pam.d/sshd && \
    ssh-keygen -A

